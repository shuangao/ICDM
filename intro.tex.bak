Learning to classify new categories from different domains is always an interesting and challenging topic in data mining. 
Previous empirical and theoretical studies have shown that the testing error is positively proportional to the difference between the test and training input distributions \cite{ben2007analysis} \cite{blitzer2008learning}. Therefore, mismatched data distribution can be a hug problem for predicting the data from a different domain. Domain adaptation is proposed to solve this problem, transferring the knowledge from the source domain to target ones. For image recognition tasks, the model trained from the source domain is inherently biased as there is no database that includes all the transformations of the images. Many domain adaptation methods have been proposed to solve this bias with shallow feature representations, assuming that there should be a strong relationship between the categories from two domains \cite{daume2009frustratingly} \cite{yang2007adapting} \cite{aytar2011tabula}. However, this assumption could fail when the algorithm try to adapt less similar categories.

Recently, Convolutional Neural Network (CNN) shows its potential to replace the shallow features, such as SIFT \cite{lowe1999object}, SURF \cite{bay2006surf} and HOG \cite{dalal2005histograms} etc, in large object recognition tasks \cite{krizhevsky2012imagenet} \cite{zeiler2014visualizing} \cite{simonyan2014very}. Unlike the local feature which presents an shallow interpretation of spatial property, deep CNN can automatically learn top-down hierarchical feature representations. Therefore, deep CNN has been intensively used as the feature extractor for image recognition \cite{farabet2013learning}. As deep feature representation has strong generalization ability, it can compensate for the data bias and be applied for domain adaptation. Fine-tuning the whole network with the pre-trained models on target domain directly has shown some impressive results from previous studies \cite{Chatfield14} \cite{zeiler2014visualizing} \cite{hoffman2013one} \cite{NIPS2014_Zhou}. 
However, fine-tuning large deep CNN with limited training data could lead to overfitting which is mostly due to the sampling noise \cite{srivastava2014dropout}.

The idea of "warm start" has been widely used for linear optimization problem, where the algorithm iteratively initializes and updates the parameters from previous steps \cite{yildirim2002warm} \cite{john2008implementation} \cite{zeilinger2011real}. Recently, Chu et al. proposed a method for parameter selection with warm start in linear classifier\cite{chuwarm}.

Since the previous methods are limited to either similar categories or requiring many labeled examples, it would be ideal for a method that can learn and predict new categories with just a few labeled training examples. In this paper, we propose an incremental adaptive approach with warm start technique to solve this problem for food image recognition. %Empirical experiments show that our method can learn new categories and achieve better result with deep representations.
There are two main contributions of our work:
\begin{enumerate}
  \item Training deep feature extractor. To generate deep representation from images, we first train the efficient feature extractor with fine-tuned GoogLeNet and achieve the state-of-the-art performance on Food-101 dataset. Compared to the results training on full dataset, we can achieve similar results while just using a few examples in each category with deep representation.
  \item Warm start for domain adaptation. We find that previous domain adaptation methods suffer as the difference between target and source domain increases. Benefitting from warm start parameters in each step, out method can achieve better result compared to cold start. Moreover, warm start parameters converges better with a few training iterations compared to cold start.
\end{enumerate}

The rest of this paper is organized as follow: In Section \ref{sec:bg} we introduce the two datasets and discuss some properties about the food recognition task. In order to obtain discriminative representations from images, we fine-tuned GoogLeNet with pre-trained parameters from ImageNet and achieve state-of-the-art performance on our source domain, Food-101 dataset in Section \ref{sec:ft}. We discuss the limitations of some previous adaptation methods and propose our warm start adaptation method for learning new categories in Section \ref{sec:da}. 