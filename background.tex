In this section, we introduce the two food datasets used in this paper and discuss the challenges of food recognition task.
\subsection{Food Datasets}
 In this paper, we use two image datasets Food-256\footnote{Dataset can be found http://foodcam.mobi/dataset.html} \cite{kawano14c} and Food-101\footnote{Dataset can be found http://www.vision.ee.ethz.ch/datasets\_extra/food-101} \cite{bossard14} for our domain adaptation task.

\textbf{Food-101 Dataset.}
This dataset contains 101-class real-world food (dish) images which were taken and labeled manually. The total number of images is 101,000 and there are exactly 1,000 images for each class. Each class is split into training and testing set containing 750 images and 250 images respectively by its collector. Since this is a big dataset with even class distribution, it is used as the source dataset as well as to train the feature extractor.

\textbf{Food-256 Dataset.}
This is a relatively small dataset containing 256 classes of foods and 31,644 images from various countries such as French, Italian, US, Chinese, Thai, Vietnamese, Japanese and Indonesia. The distribution among classes is not even and the biggest class contains 731 images while the smallest one contains just 100 images. Since this dataset contains more categories and less images per class, it is used as our target dataset.

\subsection{Challenges of food recognition task}
There are some inherent properties of the food image that makes our task challenging.
\begin{itemize}
 \item Food is a small sub-category among all general categories in daily life, so the inter-class variation is relatively small. On the other hand, the contour of a food varies depending on many aspects such as the point of the view or even its components. Domain adaptation techniques could suffer from inefficient feature representations and degrade the performance.
  \item Food doesn't have any distinctive spatial layout: for other tasks like scene recognition, we can always find some distinctive features such as buildings or trees, etc. Learning useful representation merely for food recognition itself is a complex task.
\end{itemize}
These properties requires a model that learn from local information of the images \cite{bossard2014food}. Generally, recognizing an image consists of two major parts: extracting features and predicting the label with some classifiers. Previous studies show that the first part is more important and training an efficient feature extractor could reduce the complexity of prediction greatly\cite{zeiler2014visualizing} \cite{simonyan2014very}. To achieve high accuracy for similar foods and adapt new foods, we require an efficient feature extractor that can learn both general and distinctive representations for our task. Deep CNN has achieved great progress in recent years. Deep CNNs are proved to learn hierarchical features for image recognition task from some previous work\cite{zeiler2010deconvolutional}\cite{krizhevsky2012imagenet}\cite{CiresanIJCAI11}. Compared to other shallow methods, features extracted from deep CNN can be distinguished by linear model. Therefore, we train our a deep CNN as our feature extractor in this paper and use the deep feature representations as the input of our method. In Section \ref{sec:ft}, we show the results of our fine-tuned deep CNN model on Food-101 datasets. 