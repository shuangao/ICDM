In this section, we introduce the two food dataset used in this paper and discuss the challenges of food recognition task.
\subsection{Food Datasets}
 In this paper, we use two image datasets Food-256\footnote{Dataset can be found http://foodcam.mobi/dataset.html} \cite{kawano14c} and Food-101\footnote{Dataset can be found http://www.vision.ee.ethz.ch/datasets\_extra/food-101} \cite{bossard14} for our domain adaptation task.

\textbf{Food-101 Dataset.}
This dataset contains 101-class real-world food (dish) images which were taken and labeled manually. The total number of images is 101,000 and there are exactly 1000 images for each class. Also, each class has been divided into training and testing set containing 750 images and 250 images respectively by its collector. Since this is a big dataset with even distribution for each category, it is used as the source dataset as well as to train the feature extractor.

\textbf{Food-256 Dataset.}
This is a relatively small dataset containing 256 kinds of foods and 31644 images from various countries such as French, Italian, US, Chinese, Thai, Vietnamese, Japanese and Indonesia. The distribution among classes is not even and the biggest class (vegetable tempura) contains 731 images while the smallest one contains just 100 images. Since this dataset contains more categories and less images, it is used as our target dataset.

\subsection{Challenges of food recognition task}
There are some inherent properties of the food that makes our task challenging.
\begin{itemize}
  \item Food doesn't have any distinctive spatial layout: for other tasks like scene recognition, we can always find some discriminative features such as buildings or trees, etc. Learning useful representation merely for food recognition itself is a complex task.
  \item Food category is a small sub-category among all the general categories in daily life, so the inter-class variation is relatively small; on the other hand, the contour of a food varies depending on many aspects such as the point of the view or even its components. Domain adaptation techniques could suffer from this and degrade the performance.
\end{itemize}
These properties make food recognition catastrophic for some recognition algorithms. Recognizing a image consists of two major parts: extracting features and predicting the label with some classifiers. In general, the first part is more important and training an efficient feature extractor could reduce the complexity of our task greatly. To achieve high accuracy for similar foods and adaptive for new foods, we require an efficient feature extractor that can learn both general and discriminative representations for our task. Deep CNN has achieved great progress in recent years and it is proved to learn hierarchical features for image recognition task\cite{zeiler2010deconvolutional}\cite{krizhevsky2012imagenet}\cite{CiresanIJCAI11}. Compared to other shallow methods, features extracted from deep CNN can be distinguished by linear model. Therefore, we train our a deep CNN as our feature extractor in this paper and use the deep feature representations as the input of our method. In Section \ref{sec:ft}, we show the-state-of-art performance on Food-101 datasets with deep CNN.

%Data argumentation is an efficient way to enrich the data. There are also some techniques that can applied to enlarge the dataset such as subsampling and mirroring. The original images are firstly resized to $256\times 256$ pixels. We crop the 4 corners and center for each image according to the input size of each model and flap the 5 cropped images to obtain 10 crops. For the testing set, the prediction of an image is the average prediction of the 10 crops. 