Recognizing the objects is the most fundamental function for human to understand the world, the whole procedure of which only takes a few tens of milliseconds for human brain.
Recently, Convolutional Neural Network (CNN) shows its potential to replace the human engineered features, such as SIFT \cite{lowe1999object}, SURF \cite{bay2006surf} and HOG \cite{dalal2005histograms} etc, in the large object recognition tasks\cite{krizhevsky2012imagenet}\cite{zeiler2014visualizing}\cite{simonyan2014very}. In ILSVRC2014, the 1st prize winner, referred as GoogLeNet, achieved a 93.33\% top-5 accuracy, almost as good as human annotation\cite{szegedy2014going}.
Unlike the local features such as SIFT or SURF, which present an shallow interpretation of spatial property, deep CNN can automatically learn top-down hierarchical feature representations. Therefore, deep CNN has been intensively used as the feature extractor for image recognition\cite{farabet2013learning}.
Training a large deep CNN on real recognition problem is always a complicated task. The model contains hundreds of millions of parameters to learn and lots of hyper-parameters that can affect its performance. However, continuingly expending web-based datasets such as ImageNet promises the researchers to utilize large amount of labeled images and train very deep CNNs. The truth that deep CNN outperforms other shallow models by a large margin in some real image recognition tasks encourages researchers to build deeper architecture with powerful high performance hardware and larger datasets.

Even though, these large scale web-based datasets contain almost any desired categories, it is still not possible for them to include images across all the domains that people may interest.
Domain adaptation aims to build classifiers that are robust to mismatched data distributions. Domain adaptation for image recognition 
Since deep CNN models are trained on these very large image datasets and can learn hierarchical features, they have strong generalization ability and can be applied in many other scenarios. Applying the pre-trained model from ImageNet dataset on other domains shows some impressive results.
Zeiler et al. applied their pre-trained model on Caltech-256 with just 15 instances per class and improved the previous state-of-the-art in which about 60 instances were used, by almost 10\% \cite{zeiler2014visualizing}. Chatfield et al used their pre-trained model on VOC2007 dataset and outperformed the previous state-of-the-art by 0.9\% \cite{Chatfield14}.


In this paper, we apply two kinds typical of deep CNN architecture, AlexNet and GoogLeNet, on a real specific recognition problem, food recognition, and discuss some observations in fine-tuning the existing CNN architectures on this problem. To our best knowledge, little work has done to discuss the architecture of GoogLeNet while the architecture of AlexNet has been widely studied and improved. Also, little work has been found to compare two deep CNNs with different architectures. By comparing some statistics of the weights and feature maps of these two architectures, we find that the $1\times 1$ small receptive field used in GoogLeNet can improve both computational and training efficiency which leads to the success of the whole architecture.
Then, we conduct several experiments to stimulate a real world scenario when the training labeled data is rare. The results reveal that deep CNN can work well while transferring knowledge from general recognition task to specific one in this scenario. We achieve 95\% of the accuracy trained on full dataset while just utilizing half of the dataset.

%The rest of this paper is organized as follow: in Section \ref{exp}, the two deep CNN architectures and food image datasets are introduced. In Section \ref{discuss}, some experimental results are shown and we also compare the performance between the deep CNNs as well as some traditional methods on these two datasets. And some discussion of the Inception's architecture and statistics are shown in Section \ref{discuss}. We also show some further transfer learning results when the target training examples are rare for each class.
