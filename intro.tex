Recognizing the objects is the most fundamental function for human to understand the world, the whole procedure of which only takes a few tens of milliseconds for human brain.
Recently, Convolutional Neural Network (CNN) shows its potential to replace the human engineered features, such as SIFT \cite{lowe1999object}, SURF \cite{bay2006surf} and HOG \cite{dalal2005histograms} etc, in the large object recognition tasks\cite{krizhevsky2012imagenet}\cite{zeiler2014visualizing}\cite{simonyan2014very}. In ILSVRC2014, the 1st prize winner, referred as GoogLeNet, achieved a 93.33\% top-5 accuracy, almost as good as human annotation\cite{szegedy2014going}.
Unlike the local features such as SIFT or SURF, which present an shallow interpretation of spatial property, deep CNN can automatically learn top-down hierarchical feature representations. Therefore, deep CNN has been intensively used as the feature extractor for image recognition\cite{farabet2013learning}.
Training a large deep CNN on real recognition problem is always a complicated task. The model contains hundreds of millions of parameters to learn and lots of hyper-parameters that can affect its performance. However, continuingly expending web-based datasets such as ImageNet promises the researchers to utilize large amount of labeled images and train very deep CNNs. The truth that deep CNN outperforms other shallow models by a large margin in some real image recognition tasks encourages researchers to build deeper architecture with powerful high performance hardware and larger datasets.

Even though, these large scale web-based datasets contain almost any desired categories, it is still not possible for them to include images across all the domains that people may interest.
Domain adaptation aims to build classifiers that are robust to mismatched data distributions. However, image recognition models trained from source domain are inherently biased due to the datasets. Previous empirical and theoretical studies have shown that the testing error is positively proportional to the difference between the test and training input distribution\cite{ben2007analysis}\cite{blitzer2008learning}. Many domain adaptation methods have been proposed to solve this bias, but most of them are limited to features extracted from shallow models\cite{daume2009frustratingly}\cite{yang2007adapting}\cite{aytar2011tabula}.
Since deep CNN models are trained on these very large image datasets and can learn hierarchical features, they have strong generalization ability and can be applied in many other domains. Applying the pre-trained model from ImageNet dataset to other domains without taking advantage of domain adaptation shows some impressive results\cite{Chatfield14} \cite{zeiler2014visualizing}. Some work can be found for deep learning domain adaptation, but is limited to identical categories for the source and target domain\cite{hoffman2013one}\cite{NIPS2014_Zhou}. To our best knowledge, almost none of the previous domain adaptation studies the problem while the target categories are different from the source.

In this paper, we first train the feature extractor with fine-tuned GoogLeNet on Food-101 dataset. Our fine-tuned models achieve the state-of-the-art performance and show that deep CNN can learn discriminative representations for food recognition task. We find that previous domain adaptation methods suffer when the categories in source domain and target domain are different.From empirical experiments we find that previous methods suffer from utilizing the information from source domain and show little improvement compared to other methods without adaptation techniques. We propose a online adaptive approach with warm start technique and experiment results show that our method can continuously learn new categories from target domain.

