Recognizing the objects is the most fundamental function for human to understand the world, the whole procedure of which only takes a few tens of milliseconds for human brain.
Recently, Convolutional Neural Network (CNN) shows its potential to replace the human engineered features, such as SIFT \cite{lowe1999object}, SURF \cite{bay2006surf} and HOG \cite{dalal2005histograms} etc, in the large object recognition tasks\cite{krizhevsky2012imagenet}\cite{zeiler2014visualizing}\cite{simonyan2014very}. In ILSVRC2014, the 1st prize winner, referred as GoogLeNet, achieved a 93.33\% top-5 accuracy, almost as good as human annotation\cite{szegedy2014going}.
Unlike the local features such as SIFT or SURF, which present an shallow interpretation of spatial property, deep CNN can automatically learn top-down hierarchical feature representations. Therefore, deep CNN has been intensively used as the feature extractor for image recognition\cite{farabet2013learning}.
Training a large deep CNN on real recognition problem is always a complicated task. The model contains hundreds of millions of parameters to learn and lots of hyper-parameters that can affect its performance. However, continuingly expending web-based datasets such as ImageNet promises the researchers to utilize large amount of labeled images and train very deep CNNs. The truth that deep CNN outperforms other shallow models by a large margin in some real image recognition tasks encourages researchers to build deeper architecture with powerful high performance hardware and larger datasets.

Even though, these large scale web-based datasets contain almost any desired categories, it is still not possible for them to include images across all the domains that people may interest.
Domain adaptation aims to build classifiers that are robust to mismatched data distributions. However, image recognition models trained from source domain are inherently biased due to the datasets. Previous empirical and theoretical studies have shown that the testing error is positively proportional to the difference between the test and training input distribution\cite{ben2007analysis}\cite{blitzer2008learning}. Many domain adaptation methods have been proposed to solve this bias, but most of them are limited to features extracted from shallow models\cite{daume2009frustratingly}\cite{yang2007adapting}\cite{aytar2011tabula}.
Since deep CNN models are trained on these very large image datasets and can learn hierarchical features, they have strong generalization ability and can be applied in many other domains. Applying the pre-trained model from ImageNet dataset to other domains without taking advantage of domain adaptation shows some impressive results\cite{Chatfield14} \cite{zeiler2014visualizing}. Some work can be found for deep learning domain adaptation, but is limited to identical categories for the source and target domain\cite{hoffman2013one}\cite{NIPS2014_Zhou}. Moreover, when the labeled examples are sparse, it is very difficult to train a efficient deep neural network. To our best knowledge, little the previous work studies the problem while the target categories are different from the source.

In this paper, we propose an adaptive approach with warm start technique and experiment results show that our method can continuously learn new categories with deep representations. We first train the feature extractor with fine-tuned GoogLeNet on Food-101 dataset to generate deep representation from images and achieve the state-of-the-art performance. 
We find that previous domain adaptation methods suffer as the difference between target and source domain increases. Benefitting from warm start parameters in each step, out method can achieve better result compared to cold start. Moreover, warm start parameters converges better with a few training iterations compared to cold start. 
%From empirical experiments we find that previous methods suffer from utilizing the information from source domain and show similar results compared to other methods without adaptation techniques in learning a single new category.

The rest of this paper is organized as follow: In Section \ref{sec:bg} we introduce the two datasets and discuss some properties about the food recognition task. In order to obtain discriminative representations from images, we fine-tuned GoogLeNet with pre-trained parameters from ImageNet and achieve state-of-the-art performance on our source domain, Food-101 dataset in Section \ref{sec:ft}. We discuss the limitations of some previous adaptation methods and propose our warm start adaptation method for learning new categories in Section \ref{sec:da}.
